---
title: 'Predicting Premature Death Based on Health and Socio-economic Factors'
author: 'Team Illinois: Data Analysis Project Report'
date: '08/07/2020'
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---
***

**Team Illinois Members**

  - Julia Dawson, NETID: TODO
  
  - Joseph Stewart, NETID: TODO
  
  - Saumya Singh, NETID: saumyas2
  
***

```{r setup, include=FALSE}

# Read as packages here
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
library(faraway)
library(lmtest)
library(MASS)
library(knitr)
library(kableExtra)
```

# Introduction

Due to the number of predictors in our initial dataset, we decided to try several approaches to pare down the number predictors to a manageable number. These approaches are drastically different in some ways and similar in other ways. 



# Methods
```{r}
# Util functions 

plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange", title) {
  
plot(fitted(model), resid(model), col = pointcol, pch = 20, cex = 1.5, xlab = "Fitted", ylab = "Residuals", main = title)
  abline(h = 0, col = linecol, lwd = 2)
}

plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange", title) {
  qqnorm(resid(model), main = title, col = pointcol, pch = 20, cex = 1.5)
  qqline(resid(model), col = linecol, lwd = 2)
}

plot_hist_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange", title) {
  hist(resid(model),
       xlab   = "Residuals",
       main   = title,
       col    = pointcol,
       border = linecol,
       breaks = 45)
}


get_bp = function(model) {
  bptest(model)$p.value
  #decide = unname(bptest(model)$p.value < alpha)
  #ifelse(decide, "Reject", "Fail to Reject")
}

get_sw = function(model) {
  shapiro.test(resid(model))$p.value
  #decide = unname(shapiro.test(resid(model))$p.value < alpha)
  #ifelse(decide, "Reject", "Fail to Reject")
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

get_rmse = function(model) {
  sqrt(mean(resid(model) ^ 2))
}

rmse  = function(actual, predicted) {
  sqrt(mean((actual - predicted) ^ 2))
}

get_AIC = function(model) {
  extractAIC(model)[2]
}
```

## Approach 1

## Approach 2

# Starting point
In this method, we started by selecting a small number of predictors that showed a strong connection to the response variable "Years of Potential Life Lost Rate". This selection was done based on the study of the variables from the data source https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation

This set of variables were added to smaller file to make the loading and knitting of the markdown document more efficient.

```{r}
model_2_DF = read_csv("data//Model_2_data.csv") 

model_2_DF$`WaterViol` = as.factor(model_2_DF$`WaterViol`)

model_2_DF = model_2_DF[sample(1:nrow(model_2_DF), 2000, replace=FALSE),]

# Split into test and train
indexes = sample(nrow(model_2_DF), 1000)
train_df = model_2_DF[indexes,]
test_df = model_2_DF[-indexes,]

```

- Through a pairs plot of the variables we can see that some variables appear to have collinearity issues.
- There are others that may benefit from transformations.
We will explore this further.

```{r, fig.height=10, fig.width=15}
pairs(model_2_DF)
```


- Various transformations were applied to the predictor variables and only one of them showed a marked difference from the transformation. But this variable was dropped later in the final model derived in this section.

```{r}

par(mfrow = c(2,2))

plot(model_2_DF$UnemployedPct, 
     model_2_DF$YPLLRate, 
     col = "dodgerblue", 
     pch = 20,
)

plot(log(model_2_DF$UnemployedPct), 
     model_2_DF$YPLLRate, 
     col = "dodgerblue", 
     pch = 20,
)

plot(model_2_DF$ViolsCrimeAnlAvg, 
     model_2_DF$YPLLRate, 
     col = "dodgerblue", 
     pch = 20,
)

plot(log(model_2_DF$ViolsCrimeAnlAvg), 
     model_2_DF$YPLLRate, 
     col = "dodgerblue", 
     pch = 20,
)

```

- We started by fitting a model with all predictors. **Fitted vs Residuals** plot of this model shows outliers that could be influencing the model. In the next step we removed the ouliers and can see from the **Fitted vs Residuals** and **Q-Q**plot that it greatly improved the variance distribution.

```{r}
# FULL model, with all predictors
model_2_full = lm(YPLLRate ~ . , data = model_2_DF)
```

```{r}
# Check for Outliers and Influence.
outliers = as.vector(as.integer(names(rstandard(model_2_full)[abs(rstandard(model_2_full)) > 2])))
high_influence = as.vector(which(cooks.distance(model_2_full) > 4 / length(cooks.distance(model_2_full))))

# Remove outliers
remove_noise = c(outliers, high_influence)
model_2_DF_clean = model_2_DF[-remove_noise,]

model_2_full_cl = lm(YPLLRate ~ . , data = model_2_DF_clean)
```

```{r}
(model_2_aic = step(model_2_full_cl, direction = "backward", trace=0))

```

We tried several approches to improve this model but the best model we could achieve was by applying box-cox transform to the response variable of a model selected via backward-AIC.  model 

```{r}
boxcox(model_2_aic, lambda = seq(-0.25, 0.75, by = 0.05), plotit = TRUE)
```

```{r}

model_2_cox = lm(formula = (((YPLLRate ^ 0.6) - 1) / 0.6) ~ LBWPct + ObeseAdultsPct + DrinkExcPct +  HSGradRate + DistressFreqPhysPct + HIVRate + IncHousehldMedian +  HomeownersPct, data = model_2_DF_clean)


```


**Plots**
```{r fig.height=8, fig.width=20}
par(mfrow = c(1,3))

plot_fitted_resid(model_2_full, title="Model 2 FULL")
plot_fitted_resid(model_2_full_cl, title="Model 2 FULL, Outliers removed")
plot_fitted_resid(model_2_cox, title="Model 2, Box-Cox transformed")

```


```{r}
par(mfrow = c(1,3))

plot_qq(model_2_full, title="Model 2 FULL")
plot_qq(model_2_full_cl, title="Model 2 FULL, Outliers removed")
plot_qq(model_2_cox, title="Model 2, Box-Cox transformed")

```


## Approach 3



## Model Diagnostics

```{r}

# Model 1
info_1 = c(get_bp(model_2_cox), get_sw(model_2_cox), get_num_params(model_2_cox), get_loocv_rmse(model_2_cox), get_adj_r2(model_2_cox), get_rmse(model_2_cox), get_AIC(model_2_cox))

# Model 2
info_2 = c(get_bp(model_2_cox), get_sw(model_2_cox), get_num_params(model_2_cox), get_loocv_rmse(model_2_cox), get_adj_r2(model_2_cox), get_rmse(model_2_cox), get_AIC(model_2_cox))

# Model 3
info_3 = c(get_bp(model_2_cox), get_sw(model_2_cox), get_num_params(model_2_cox), get_loocv_rmse(model_2_cox), get_adj_r2(model_2_cox), get_rmse(model_2_cox), get_AIC(model_2_cox))

model_info = cbind(info_1, info_2, info_3)

rownames(model_info) = c("BP Test", "Shapiro","No params", "LOOV RMSE", "Adj R2", "RMSE", "AIC")
colnames(model_info) = c("Model 1", "Model 2", "Model 3")

knitr::kable(model_info) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


# Results

# Discussion

# Appendix
